{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File needs to be a **csv** of the following format:\n",
    "\n",
    "```\n",
    "item1, item2, item3, ... so on\n",
    " , t, ...\n",
    "t, t, t,...\n",
    "t, t, ...\n",
    "... so on...```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>handphone</th>\n",
       "      <th>laptop</th>\n",
       "      <th>charger</th>\n",
       "      <th>powerbank</th>\n",
       "      <th>tablet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  handphone laptop charger powerbank tablet\n",
       "0         t      t     NaN       NaN    NaN\n",
       "1         t      t       t       NaN    NaN\n",
       "2         t      t       t         t    NaN\n",
       "3         t      t     NaN       NaN      t\n",
       "4         t    NaN       t       NaN      t"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"test1.csv\", low_memory=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'handphone': 1, 'laptop': 2, 'charger': 3, 'powerbank': 4, 'tablet': 5}"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_list = list(df.columns)\n",
    "item_dict = dict()\n",
    "\n",
    "for i, item in enumerate(item_list):\n",
    "    item_dict[item] = i + 1\n",
    "\n",
    "item_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{1, 2},\n",
       " {1, 2, 3},\n",
       " {1, 2, 3, 4},\n",
       " {1, 2, 5},\n",
       " {1, 3, 5},\n",
       " {4, 5},\n",
       " {1, 2, 3, 5},\n",
       " {1, 3},\n",
       " {1, 4},\n",
       " {2, 3, 4}]"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions = list()\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    transaction = set()\n",
    "    \n",
    "    for item in item_dict:\n",
    "        if row[item] == 't':\n",
    "            transaction.add(item_dict[item])\n",
    "    transactions.append(transaction)\n",
    "    \n",
    "transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initial_support(transactions, item_set):\n",
    "    transactionIDs = []\n",
    "    match_count = 0\n",
    "    transactionID = 0\n",
    "    for transaction in transactions:\n",
    "        if item_set.issubset(transaction):\n",
    "            match_count += 1\n",
    "            transactionIDs.append(transactionID)\n",
    "        transactionID += 1\n",
    "\n",
    "    return float(match_count/len(transactions)), transactionIDs\n",
    "\n",
    "\n",
    "def get_support(transactions, transactionIDs, item_set):\n",
    "    match_count = 0\n",
    "    newTransactionIDs = []\n",
    "    for transactionID in transactionIDs:\n",
    "        if item_set.issubset(transactions[transactionID]):\n",
    "            match_count += 1\n",
    "            newTransactionIDs.append(transactionID)\n",
    "            \n",
    "    return float(match_count / len(transactionIDs)), newTransactionIDs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_join(frequent_item_sets_per_level, level):\n",
    "    current_level_candidates = list()\n",
    "    last_level_items = frequent_item_sets_per_level[level - 1]\n",
    "    \n",
    "    if len(last_level_items) == 0:\n",
    "        return current_level_candidates\n",
    "    \n",
    "    for i in range(len(last_level_items)):\n",
    "        for j in range(i+1, len(last_level_items)):\n",
    "            itemset_i = last_level_items[i][0]\n",
    "            itemset_j = last_level_items[j][0]\n",
    "            union_set = itemset_i.union(itemset_j)\n",
    "            \n",
    "            if union_set not in current_level_candidates and len(union_set) == level:\n",
    "                current_level_candidates.append(union_set)\n",
    "                \n",
    "    return current_level_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_drop_subsets(item_set):\n",
    "    single_drop_subsets = list()\n",
    "    for item in item_set:\n",
    "        temp = item_set.copy()\n",
    "        temp.remove(item)\n",
    "        single_drop_subsets.append(temp)\n",
    "        \n",
    "    return single_drop_subsets\n",
    "\n",
    "def is_valid_set(item_set, prev_level_sets):\n",
    "    single_drop_subsets = get_single_drop_subsets(item_set)\n",
    "    \n",
    "    for single_drop_set in single_drop_subsets:\n",
    "        if single_drop_set not in prev_level_sets:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def pruning(frequent_item_sets_per_level, level, candidate_set):\n",
    "    post_pruning_set = list()\n",
    "    if len(candidate_set) == 0:\n",
    "        return post_pruning_set\n",
    "    \n",
    "    prev_level_sets = list()\n",
    "    for item_set, _, _ in frequent_item_sets_per_level[level - 1]:\n",
    "        prev_level_sets.append(item_set)\n",
    "        \n",
    "    for item_set in candidate_set:\n",
    "        if is_valid_set(item_set, prev_level_sets):\n",
    "            post_pruning_set.append(item_set)\n",
    "            \n",
    "    return post_pruning_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Apriori Improved Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def apriori(min_support):\n",
    "    frequent_item_sets_per_level = defaultdict(list)\n",
    "    print(\"level : 1\", end = \" \")\n",
    "    \n",
    "    for item in range(1, len(item_list) + 1):\n",
    "        support, transactionIDs = get_initial_support(transactions, {item})\n",
    "        if support >= min_support:\n",
    "            frequent_item_sets_per_level[1].append(({item}, support, transactionIDs))\n",
    "        \n",
    "    for level in range(2, len(item_list) + 1):\n",
    "        print(level, end = \" \")\n",
    "        current_level_candidates = self_join(frequent_item_sets_per_level, level)\n",
    "\n",
    "        post_pruning_candidates = pruning(frequent_item_sets_per_level, level, current_level_candidates)\n",
    "        if len(post_pruning_candidates) == 0:\n",
    "            break\n",
    "\n",
    "        for item_set in post_pruning_candidates:\n",
    "            min_support = 1\n",
    "            selected_item_transactionIDs = []\n",
    "            for item in item_set:\n",
    "                for tuple_item in frequent_item_sets_per_level[1]:\n",
    "                    if item in tuple_item[0]: \n",
    "                        if (min_support > tuple_item[1]):\n",
    "                            min_support =  tuple_item[1]\n",
    "                            selected_item_transactionIDs = tuple_item[2]\n",
    "                        break\n",
    "            support, transactionIDs = get_support(transactions, selected_item_transactionIDs,  item_set)\n",
    "            if support >= min_support:\n",
    "                frequent_item_sets_per_level[level].append((item_set, support, transactionIDs))\n",
    "                \n",
    "    return frequent_item_sets_per_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level : 1 2 3 4 "
     ]
    }
   ],
   "source": [
    "min_support = 0.005\n",
    "frequent_item_sets_per_level = apriori(min_support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "9\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for level in frequent_item_sets_per_level:\n",
    "    print(len(frequent_item_sets_per_level[level]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[({1}, 0.8, [0, 1, 2, 3, 4, 6, 7, 8]), ({2}, 0.6, [0, 1, 2, 3, 6, 9]), ({3}, 0.6, [1, 2, 4, 6, 7, 9]), ({4}, 0.4, [2, 5, 8, 9]), ({5}, 0.4, [3, 4, 5, 6])]\n",
      "[({1, 2}, 0.8333333333333334, [0, 1, 2, 3, 6]), ({1, 3}, 0.8333333333333334, [1, 2, 4, 6, 7]), ({1, 4}, 0.5, [2, 8]), ({1, 5}, 0.75, [3, 4, 6]), ({2, 3}, 0.6666666666666666, [1, 2, 6, 9]), ({2, 4}, 0.5, [2, 9]), ({2, 5}, 0.5, [3, 6]), ({3, 4}, 0.5, [2, 9]), ({3, 5}, 0.5, [4, 6])]\n",
      "[({1, 2, 5}, 0.5, [3, 6]), ({1, 3, 5}, 0.5, [4, 6]), ({2, 3, 4}, 0.5, [2, 9])]\n"
     ]
    }
   ],
   "source": [
    "for level in frequent_item_sets_per_level:\n",
    "    print(frequent_item_sets_per_level[level])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Generating Association Rules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_support_dict = dict()\n",
    "item_list = list()\n",
    "\n",
    "key_list = list(item_dict.keys())\n",
    "val_list = list(item_dict.values())\n",
    "\n",
    "for level in frequent_item_sets_per_level:\n",
    "    for set_support_pair in frequent_item_sets_per_level[level]:\n",
    "        for i in set_support_pair[0]:\n",
    "            item_list.append(key_list[val_list.index(i)])\n",
    "        item_support_dict[frozenset(item_list)] = set_support_pair[1]\n",
    "        item_list = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{frozenset({'handphone'}): 0.8,\n",
       " frozenset({'laptop'}): 0.6,\n",
       " frozenset({'charger'}): 0.6,\n",
       " frozenset({'powerbank'}): 0.4,\n",
       " frozenset({'tablet'}): 0.4,\n",
       " frozenset({'handphone', 'laptop'}): 0.8333333333333334,\n",
       " frozenset({'charger', 'handphone'}): 0.8333333333333334,\n",
       " frozenset({'handphone', 'powerbank'}): 0.5,\n",
       " frozenset({'handphone', 'tablet'}): 0.75,\n",
       " frozenset({'charger', 'laptop'}): 0.6666666666666666,\n",
       " frozenset({'laptop', 'powerbank'}): 0.5,\n",
       " frozenset({'laptop', 'tablet'}): 0.5,\n",
       " frozenset({'charger', 'powerbank'}): 0.5,\n",
       " frozenset({'charger', 'tablet'}): 0.5,\n",
       " frozenset({'handphone', 'laptop', 'tablet'}): 0.5,\n",
       " frozenset({'charger', 'handphone', 'tablet'}): 0.5,\n",
       " frozenset({'charger', 'laptop', 'powerbank'}): 0.5}"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_support_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**find_subset** finds all the subsets of the given itemset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_subset(item, item_length):\n",
    "    combs = []\n",
    "    for i in range(1, item_length + 1):\n",
    "        combs.append(list(combinations(item, i)))\n",
    "        \n",
    "    subsets = []\n",
    "    for comb in combs:\n",
    "        for elt in comb:\n",
    "            subsets.append(elt)\n",
    "            \n",
    "    return subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**association_rules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "def association_rules(min_confidence, support_dict):\n",
    "    rules = list()\n",
    "    for item, support in support_dict.items():\n",
    "        item_length = len(item)\n",
    "       \n",
    "        if item_length > 1:\n",
    "            subsets = find_subset(item, item_length)\n",
    "           \n",
    "            for A in subsets:\n",
    "                B = item.difference(A)\n",
    "               \n",
    "                if B:\n",
    "                    A = frozenset(A)\n",
    "                    \n",
    "                    AB = A | B\n",
    "                    \n",
    "                    confidence = support_dict[AB] / support_dict[A]\n",
    "                    if confidence >= min_confidence:\n",
    "                        rules.append((A, B, confidence))\n",
    "    \n",
    "    return rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify Minimum confidence value here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "association_rules = association_rules(min_confidence = 0.6, support_dict = item_support_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Printing the output in the required format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rules:  36 \n",
      "\n",
      "{'laptop'} -> {'handphone'} <confidence: 1.388888888888889>\n",
      "{'handphone'} -> {'laptop'} <confidence: 1.0416666666666667>\n",
      "{'charger'} -> {'handphone'} <confidence: 1.388888888888889>\n",
      "{'handphone'} -> {'charger'} <confidence: 1.0416666666666667>\n",
      "{'powerbank'} -> {'handphone'} <confidence: 1.25>\n",
      "{'handphone'} -> {'powerbank'} <confidence: 0.625>\n",
      "{'tablet'} -> {'handphone'} <confidence: 1.875>\n",
      "{'handphone'} -> {'tablet'} <confidence: 0.9375>\n",
      "{'laptop'} -> {'charger'} <confidence: 1.1111111111111112>\n",
      "{'charger'} -> {'laptop'} <confidence: 1.1111111111111112>\n",
      "{'laptop'} -> {'powerbank'} <confidence: 0.8333333333333334>\n",
      "{'powerbank'} -> {'laptop'} <confidence: 1.25>\n",
      "{'laptop'} -> {'tablet'} <confidence: 0.8333333333333334>\n",
      "{'tablet'} -> {'laptop'} <confidence: 1.25>\n",
      "{'charger'} -> {'powerbank'} <confidence: 0.8333333333333334>\n",
      "{'powerbank'} -> {'charger'} <confidence: 1.25>\n",
      "{'tablet'} -> {'charger'} <confidence: 1.25>\n",
      "{'charger'} -> {'tablet'} <confidence: 0.8333333333333334>\n",
      "{'laptop'} -> {'tablet', 'handphone'} <confidence: 0.8333333333333334>\n",
      "{'tablet'} -> {'laptop', 'handphone'} <confidence: 1.25>\n",
      "{'handphone'} -> {'laptop', 'tablet'} <confidence: 0.625>\n",
      "{'laptop', 'tablet'} -> {'handphone'} <confidence: 1.0>\n",
      "{'laptop', 'handphone'} -> {'tablet'} <confidence: 0.6>\n",
      "{'tablet', 'handphone'} -> {'laptop'} <confidence: 0.6666666666666666>\n",
      "{'tablet'} -> {'charger', 'handphone'} <confidence: 1.25>\n",
      "{'charger'} -> {'tablet', 'handphone'} <confidence: 0.8333333333333334>\n",
      "{'handphone'} -> {'tablet', 'charger'} <confidence: 0.625>\n",
      "{'tablet', 'charger'} -> {'handphone'} <confidence: 1.0>\n",
      "{'tablet', 'handphone'} -> {'charger'} <confidence: 0.6666666666666666>\n",
      "{'charger', 'handphone'} -> {'tablet'} <confidence: 0.6>\n",
      "{'laptop'} -> {'charger', 'powerbank'} <confidence: 0.8333333333333334>\n",
      "{'charger'} -> {'laptop', 'powerbank'} <confidence: 0.8333333333333334>\n",
      "{'powerbank'} -> {'laptop', 'charger'} <confidence: 1.25>\n",
      "{'laptop', 'charger'} -> {'powerbank'} <confidence: 0.75>\n",
      "{'laptop', 'powerbank'} -> {'charger'} <confidence: 1.0>\n",
      "{'charger', 'powerbank'} -> {'laptop'} <confidence: 1.0>\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rules: \", len(association_rules), \"\\n\")\n",
    "\n",
    "for rule in association_rules:\n",
    "    print('{0} -> {1} <confidence: {2}>'.format(set(rule[0]), set(rule[1]), rule[2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
